{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import nltk\n",
      "import random"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "comments_df = pd.read_csv(\"may2015equallyspaced.csv\")\n",
      "comments_df = comments_df.drop(['created_utc', 'subreddit_id', 'name', 'score_hidden', 'author_flair_css_class', \\\n",
      "                                'author_flair_text', 'removal_reason', 'gilded', 'archived', 'downs', 'score', \\\n",
      "                                'retrieved_on', 'distinguished', 'edited', 'controversiality', 'parent_id'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sample = comments_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def subreddit_words(subreddit):\n",
      "    result = []\n",
      "    for comment in sample[sample.subreddit.apply(lambda x: x.lower()) == subreddit.lower()].body:\n",
      "        comment = str(comment).decode('utf-8')\n",
      "        comment = comment.replace('\\\\n', ' ')\n",
      "        result = result + comment.lower().split()\n",
      "    return result"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arwords = subreddit_words('askreddit')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>N-GRAM MADNESS</h1>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar5 = list(nltk.ngrams(arwords, 5))\n",
      "ar_grouped5 = [((x[0], x[1], x[2], x[3]), x[4]) for x in ar5]\n",
      "ar4 = list(nltk.ngrams(arwords, 4))\n",
      "ar_grouped4 = [((x[0], x[1], x[2]), x[3]) for x in ar4]\n",
      "ar3 = list(nltk.ngrams(arwords, 3))\n",
      "ar_grouped3 = [((x[0], x[1]), x[2]) for x in ar3]\n",
      "ar2 = list(nltk.ngrams(arwords, 2))\n",
      "ar_grouped2 = [((x[0]), x[1]) for x in ar2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar_cfd5 = nltk.ConditionalFreqDist(ar_grouped5)\n",
      "ar_cfd4 = nltk.ConditionalFreqDist(ar_grouped4)\n",
      "ar_cfd3 = nltk.ConditionalFreqDist(ar_grouped3)\n",
      "ar_cfd2 = nltk.ConditionalFreqDist(ar_grouped2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#(1,2,...,n) -> ((1,2,...,n-1),n)\n",
      "def ngram_generator(n, cfdist, phrase, num=15, print_choices=True):\n",
      "    if(n==2):\n",
      "        print(phrase, end=' ')\n",
      "    else:\n",
      "        for word in phrase:\n",
      "            print(word, end=' ')\n",
      "    for i in range(num):\n",
      "        try:\n",
      "            #maximum of ten choices\n",
      "            topten = [x[0] for x in cfdist[phrase].most_common(10)]\n",
      "            if print_choices:\n",
      "                print(topten)\n",
      "            sum_count = sum(cfdist[phrase][w] for w in topten)\n",
      "            probs = [float(cfdist[phrase][w])/sum_count for w in topten]\n",
      "            choice = np.random.choice(a=range(len(probs)), p=probs)\n",
      "            print(topten[choice], end=' ')\n",
      "            #phrase = (phrase[i] for i in range(1,n-1), topfive[choice]) #remember this does not include n-1\n",
      "            if(n==4): #hack\n",
      "                phrase = (phrase[1], phrase[2], topten[choice])\n",
      "            if(n==3):\n",
      "                phrase = (phrase[1], topten[choice])\n",
      "            if(n==2):\n",
      "                phrase = (topten[choice])\n",
      "        except ValueError:\n",
      "            print('DEAD END')\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_generator(4, art_cfd4, ('make', 'sure', 'you'), num=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "make sure you [u'have', u'attend', u'get', u\"don't\", u'watch', u'try', u'know', u'were', u'are']\n",
        "watch [u'leon:']\n",
        "leon: [u'the']\n",
        "the [u'professional']\n",
        "professional [u'(on', u'was']\n",
        "was [u'released']\n",
        "released [u'as']\n",
        "as [u'the']\n",
        "the [u'professional']\n",
        "professional [u'in']\n",
        "in [u'na.']\n",
        "na. [u'parts']\n",
        "parts [u'of']\n",
        "of [u'it']\n",
        "it [u'and', u\"didn't\"]\n",
        "and [u\"i'll\", u'then', u\"i'm\", u'just']\n",
        "then [u'i', u'tried', u'realise']\n",
        "i [u'will', u'can', u'shave', u\"couldn't\", u'just', u\"don't\", u'fucking', u'have', u'saw', u'find']\n",
        "saw [u'something.']\n",
        "something. [u'i']\n",
        "i [u'moved']\n",
        "moved [u'my']\n",
        "my [u'flashlight']\n",
        "flashlight [u'to']\n",
        "to [u'catch']\n",
        "catch [u'this']\n",
        "this [u'large,']\n",
        "large, [u'black']\n",
        "black [u'creature']\n",
        "creature [u'that']\n",
        "that [u'was']\n",
        "was [u'moving']\n",
        "moving [u'at']\n",
        "at [u'an']\n",
        "an [u'incredible']\n",
        "incredible [u'pace.']\n",
        "pace. [u'it']\n",
        "it [u'moved']\n",
        "moved [u'quickly,']\n",
        "quickly, [u'and']\n",
        "and [u'it']\n",
        "it [u'came']\n",
        "came [u'out', u'to', u'around']\n",
        "out [u'i', u'on', u'great', u'as', u'5', u'in', u'the']\n",
        "on [u'pc.', u'her']\n",
        "her [u'show.']\n",
        "show. [u'the']\n",
        "the [u'irony']\n",
        "irony [u'is,']\n",
        "is, [u'plenty']\n",
        "plenty "
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_generator(4, art_cfd4, ('make', 'sure', 'you'), num=250, print_choices=False)\n",
      "print('\\n\\n')\n",
      "ngram_generator(3, art_cfd3, ('make', 'sure'), num=250, print_choices=False)\n",
      "print('\\n\\n')\n",
      "ngram_generator(2, art_cfd2, (('make')), num=250, print_choices=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "make sure you attend an accredited program. pm me if you try to swing an axe at shia labeouf, but blood is draining fast from your stump leg. *jet fuel can't melt steel beams. [deleted] and i wouldn't put it in contest mode, op what country am i in? people actually make smores in the microwave? hippies the books are indeed hella good, but they're also quite long so you've gotta be prepared for a lack of smarts or skill in the subject, but rather a lot of my relationships suffered because of this. my new neighborhood isn't much better but it isn't just me either. the urinal *always* has a puddle around it unless it has just been getting better. hot taco mom? the book firefly by piers anthony is pretty messed up in a meeting one day and said \"what if we had a guy who knows a guy who wants too little from life, might not get anything at all. not too long ago. i think the most relevant answer to \"qwerzishurr\"s question. [deleted] simple arithmetic. one that i've done forever, and maybe everyone grasps but finds redundant deals with multiplying by five. 5x9? half of nine is 4.5, remove decimal, 45. 386x5? half of 386 is 193.0, remove decimal, 1930. that's just one of those is not like the family i have-- the friends i had back in high school. it was a bit of a pain in the right way, otherwise its like shoving a usb in upside \n",
        "\n",
        "\n",
        "make sure to depersonalize your question if necessary (adding context or clarification should be able to make sure to depersonalize your question nothing because we had to do with the **[serious] replies only** tag, therefore [any replies that are jokes, puns, off-topic, or are otherwise non-contributory will be removed. i'm envisioning a mad man. nothing would stop me. i love to see a dead man taxes? because that's too hard your degree was. that said, if you think about what they are just more private). i was"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " in a lot in rwanda. no cure. nasty cunt of a lot of people from having murder be illegal.* otoh if we had the same time. most people are trying to be a lot of the first thing that changed was that one-liner and he just had lunch and told me the most popular guy around. it doesn't seem to be a bit of research on the other day and i can see you tried as an aberration, people will be removed. if the idea of the most effective way to the mods! thanks for the same thing with asian parents. they have a few years and you have no idea what happened. he says he cant find the one you want a 2 define interesting. i cut my entire outfit it a dream, every time. and i will go on the side of things but sadly the contents (which can be very precise. like you said, the morning with my friends were in the \n",
        "\n",
        "\n",
        "make sure the moderators of it was so many times when i can tell my own answer your cooperation and then we have a couple of my own post. your own a great people who has the same thing for the only a bit of the"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " same thing for me. my wife is no idea to go for a very very hard for a lot of the only the only a new post that they would be removed](http://www.reddit.com/r/askreddit/wiki/index#wiki_--.5bserious.5d_tags--). if it's not the most of a lot of a good looking for your own with no one of the most of the first time in the first time to be able to be a little more about it. it as much more about a little"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " to make you know i just so much as long as a bit in the most of people i just don't know how many years. the same in the most of the moderators of the same time i was a few of their own post. your mind, at my dad and the same as long time it was a few years ago. my dad would be able to my mom has been a little"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " bit less likely not sure you don't think of the most of a great day for me the only reason i had some of the most of the same thing for some of a bit of my life is a lot of a few of a little bit on their kids in a "
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#More generating, less quoting: if there aren't enough choices for the next word at the n-gram level, revert to the\n",
      "#(n-1)-gram level\n",
      "def ngram_generator2(phrase, cfds, num=15, threshold=3, verbose=True):\n",
      "    if(num>0):\n",
      "        try:\n",
      "            level = 5\n",
      "            used_phrase = phrase\n",
      "            used_dist = cfds[0]\n",
      "            topten = [x[0] for x in used_dist[used_phrase].most_common(10)]\n",
      "            if(len(topten) < threshold):\n",
      "                level = 4\n",
      "                used_phrase = (used_phrase[1], used_phrase[2], used_phrase[3])\n",
      "                used_dist = cfds[1]\n",
      "                topten = [x[0] for x in used_dist[used_phrase].most_common(10)]\n",
      "                if(len(topten) < threshold):\n",
      "                    level = 3\n",
      "                    used_phrase = (used_phrase[1], used_phrase[2])\n",
      "                    used_dist = cfds[2]\n",
      "                    topten = [x[0] for x in used_dist[used_phrase].most_common(10)]\n",
      "                    if(len(topten) < threshold):\n",
      "                        level = 2\n",
      "                        used_phrase = (used_phrase[1])\n",
      "                        used_dist = cfds[3]\n",
      "                        topten = [x[0] for x in used_dist[used_phrase].most_common(10)]\n",
      "                \n",
      "            sum_count = sum(used_dist[used_phrase][w] for w in topten)\n",
      "            probs = [float(used_dist[used_phrase][w])/sum_count for w in topten]\n",
      "            choice = np.random.choice(a=range(len(probs)), p=probs)\n",
      "        except ValueError:\n",
      "            print('DEAD END')\n",
      "            return\n",
      "        \n",
      "        if(verbose):\n",
      "            print(level, end=' ')       \n",
      "            print(used_phrase, end=' ')\n",
      "            print(topten)\n",
      "        else:\n",
      "            print(topten[choice], end=' ')\n",
      "        \n",
      "        new_phrase = (phrase[1], phrase[2], phrase[3], topten[choice])\n",
      "        ngram_generator2(new_phrase, cfds, num-1, threshold, verbose)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ar_cfds = [ar_cfd5, ar_cfd4, ar_cfd3, ar_cfd2]\n",
      "ngram_generator2(('make', 'sure', 'you', 'have'), ar_cfds, num=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 ('make', 'sure', 'you', 'have') [u'to', u'your', u'long', u'no']\n",
        "4 ('you', 'have', u'no') [u'idea', u'control', u'high', u'use', u'right', u'choice', u'soul.', u'excuse', u'other', u'health']\n",
        "4 ('have', u'no', u'idea') [u'what', u'why', u'how', u'who', u'why,', u'i', u'of', u\"what's\", u'or', u'where']\n",
        "5 ('have', u'no', u'idea', u'how') [u'long', u'much', u'so', u'picking', u'or', u'he']\n",
        "3 (u'how', u'much') [u'of', u'it', u'i', u'money', u'you', u'is', u'more', u'that', u'they', u'better']\n",
        "4 (u'how', u'much', u'i') [u'teased', u'hate', u'needed.', u'pay', u'won,', u'shake,']\n",
        "level 2 top ten len is2\n",
        "2 teased [u'unmercifully.', u'her']\n",
        "level 2 top ten len is10\n",
        "2 her [u'and', u'to', u'a', u'in', u'for', u'own', u'that', u'with', u'car', u'life']\n",
        "3 (u'her', u'in') [u'the', u'a', u'what', u'to', u'her', u'no', u'it', u'downtown', u'hospice', u'strange']\n",
        "3 (u'in', u'a') [u'way', u'very', u'lot', u'few', u'car', u'row', u'small', u'public', u'while.', u'while']\n",
        "4 (u'in', u'a', u'few') [u'uh-huhs', u'years:', u'fields.', u'fields', u'seconds.', u'scenarios', u'years,', u'years.', u'minutes']\n",
        "4 (u'a', u'few', u'minutes') [u'before', u'and', u'ago', u'we', u'later', u'to', u'go', u'our', u'riffing']\n",
        "3 (u'minutes', u'before') [u'getting', u'i', u'it', u'waking', u'ingesting.', u'she', u'speeding', u'you', u'my']\n",
        "level 2 top ten len is9\n",
        "2 waking [u'up', u'up.', u'up,', u'her', u'hours', u'moment,', u'you', u'him', u'minute']\n",
        "3 (u'waking', u'up') [u'and', u'to', u'on', u'just', u'each', u'at', u'in', u'the']\n",
        "4 (u'waking', u'up', u'and') [u'my', u'wandering', u'breakfast.']\n",
        "3 (u'and', u'my') [u'friend', u'dad', u'parents', u'friends', u'best', u'brother', u'first', u'family', u'gf', u'ex']\n",
        "4 (u'and', u'my', u'parents') [u\"don't\", u'avoided', u'split', u'would', u'are']\n",
        "level 2 top ten len is4\n",
        "2 avoided [u'anything', u'putting', u'although', u'but']\n",
        "level 2 top ten len is10\n",
        "2 anything [u'else', u'to', u'about', u'that', u'like', u'i', u'in', u'but', u'you', u'else.']\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_generator2(('make', 'sure', 'you', 'have'), ar_cfds, num=20, threshold=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "5 ('make', 'sure', 'you', 'have') [u'to', u'your', u'long', u'no']\n",
        "5 ('sure', 'you', 'have', u'to') [u'be']\n",
        "5 ('you', 'have', u'to', u'be') [u'in', u'blind', u'25', u'blunt.', u'that', u'very', u'reasonably', u'stoned', u'able', u'up']\n",
        "5 ('have', u'to', u'be', u'that') [u'wwi']\n",
        "5 (u'to', u'be', u'that', u'wwi') [u'was']\n",
        "5 (u'be', u'that', u'wwi', u'was') [u'the']\n",
        "5 (u'that', u'wwi', u'was', u'the') [u'time']\n",
        "5 (u'wwi', u'was', u'the', u'time') [u'in']\n",
        "5 (u'was', u'the', u'time', u'in') [u'which']\n",
        "5 (u'the', u'time', u'in', u'which') [u'you']\n",
        "5 (u'time', u'in', u'which', u'you') [u'thrive.']\n",
        "5 (u'in', u'which', u'you', u'thrive.') [u\"it's\"]\n",
        "5 (u'which', u'you', u'thrive.', u\"it's\") [u'been']\n",
        "5 (u'you', u'thrive.', u\"it's\", u'been') [u'a']\n",
        "5 (u'thrive.', u\"it's\", u'been', u'a') [u'while']\n",
        "5 (u\"it's\", u'been', u'a', u'while') [u'since']\n",
        "5 (u'been', u'a', u'while', u'since') [u'i', u\"i've\"]\n",
        "5 (u'a', u'while', u'since', u\"i've\") [u'taken', u'played']\n",
        "5 (u'while', u'since', u\"i've\", u'played') [u'it,']\n",
        "5 (u'since', u\"i've\", u'played', u'it,') [u'but']\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_generator2(('make', 'sure', 'you', 'have'), ar_cfds, num=20, threshold=11)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2 have [u'a', u'to', u'any', u'been', u'the', u'no', u'an', u'never', u'you', u'some']\n",
        "2 a [u'lot', u'few', u'good', u'little', u'bot,', u'bit', u'couple', u'great', u'very', u'new']\n",
        "2 few [u'years', u'days', u'weeks', u'times', u'months', u'of', u'people', u'years.', u'minutes', u'hours']\n",
        "2 minutes [u'of', u'later', u'before', u'and', u'to', u'after', u'ago', u'later,', u'because', u'in']\n",
        "2 and [u'i', u'the', u'then', u'it', u'a', u'this', u'they', u'you', u'he', u'not']\n",
        "2 he [u'was', u'is', u'had', u'would', u\"didn't\", u'has', u'said', u'could', u'got', u'just']\n",
        "2 just [u'a', u\"don't\", u'the', u'because', u'to', u'like', u'be', u'want', u'as', u'so']\n",
        "2 to [u'be', u'the', u'get', u'do', u'a', u'make', u'go', u'have', u'see', u'my']\n",
        "2 get [u'a', u'the', u'to', u'it', u'in', u'into', u'out', u'that', u'me', u'some']\n",
        "2 the [u'same', u'first', u'best', u'only', u'other', u'moderators', u'most', u'time', u'way', u'question']\n",
        "2 best [u'way', u'of', u'friend', u'thing', u'to', u'friends', u'part', u'in', u'person', u'day']\n",
        "2 of [u'the', u'a', u'my', u'this', u'people', u'your', u'it', u'those', u'them', u'their']\n",
        "2 people [u'who', u'are', u'in', u'to', u'have', u'that', u'like', u\"don't\", u'would', u'i']\n",
        "2 who [u'is', u'are', u'was', u'have', u'had', u'has', u'would', u'you', u'i', u\"don't\"]\n",
        "2 had [u'a', u'to', u'the', u'been', u'no', u'an', u'some', u'never', u'it', u'one']\n",
        "2 a [u'lot', u'few', u'good', u'little', u'bot,', u'bit', u'couple', u'great', u'very', u'new']\n",
        "2 new [u'york', u'post', u'one', u'job', u'to', u'one.', u'people', u'york.', u'and', u'vegas.']\n",
        "2 to [u'be', u'the', u'get', u'do', u'a', u'make', u'go', u'have', u'see', u'my']\n",
        "2 make [u'a', u'sure', u'it', u'the', u'me', u'you', u'them', u'my', u'up', u'an']\n",
        "2 sure [u'to', u'if', u'you', u'that', u'i', u'how', u'it', u'the', u\"it's\", u'what']\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_generator2(('make', 'sure', 'you', 'have'), ar_cfds, num=200, threshold=2, verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "your nostalgia glasses with my mom a few years after moving in the pressure tank man who was being pressured to the point where it'd totally be worth the trouble. began to breathe fire. were all so overpowered the same as going to get hurt.\" bruises everywhere, the time and the refills bob ross is a good tip from the text box. any queries or the money and how to keep that pain and not be homeless. you can see why they don't know how to connect with people again. made it ten minutes it is for little brother one of the following reasons: * **you must post the question or include a question mark (\"?\") in my life together and hang your title. reddit isn't as big as it may seem. i think that letting herself and another building a team. my own and also do basic thing that has ever happened to me before. i just got the joke. christ. they have to admit that the op of people do too lazy to do it. as if i did it, but they don't... which i have been) on the same bus boy. i finally dive our own giant "
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def ngram_subcfds(subreddit):\n",
      "    sub_wordlist = subreddit_words(subreddit)\n",
      "    raw_lists = [nltk.ngrams(sub_wordlist, i) for i in range(2,6)]\n",
      "    sub_grouped5 = [((x[0], x[1], x[2], x[3]), x[4]) for x in raw_lists[3]]\n",
      "    sub_grouped4 = [((x[0], x[1], x[2]), x[3]) for x in raw_lists[2]]\n",
      "    sub_grouped3 = [((x[0], x[1]), x[2]) for x in raw_lists[1]]\n",
      "    sub_grouped2 = [((x[0]), x[1]) for x in raw_lists[0]]\n",
      "    return [nltk.ConditionalFreqDist(grouped) for grouped in [sub_grouped5, sub_grouped4, sub_grouped3, sub_grouped2]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#At last!\n",
      "def ngram_subgenerator(subreddit, length, temp):\n",
      "    subcfds = ngram_subcfds(subreddit)\n",
      "    phrase = subcfds[0].keys()[random.randint(0, len(subcfds[0])-1)]\n",
      "    print(phrase)\n",
      "    ngram_generator2(phrase, subcfds, num=length, threshold=temp, verbose=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='askreddit', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'opinion.', u'99.9%', u'of', u'people')\n",
        "in my family are teachers. that's why i said that it's rubbing together, or not you can do it. i couldn't get them to choose all of your choices. i think the hard way. i'm low-energy, man. i am so glad and i have to stay in a bit and have a wander or something. that sort of name is just a hivemind or your cousin don't like how most men treat the d, it's just that all i would go back just don't like how they join the cast of real emotion anyway). i have to do that involves ridding the time and money on fat people who just drop dead that you can use the argument that wasn't that way since i'm not from the us, can go a day after. this is what happens when supercapital ships being in a poor review request&amp;amp;message=my post that is a good day at the same thing as too long... just so many straight people in this town and start seizing was performed automatically. please report them to the mods! thanks for your cooperation and they have a sushi restaurant that says comes up a fifth of jose cuervo tequila. so, for most private jet, maybe i'm this is what is usually not to mention that it was our lives out on our cheap to live with that. have you heard any questions or concerns.* i think you are my only ally oops to my house after he did 20 and 50 years ago. architecture unless you are a troll account info, and asked if anyone gets to be a few things that i will never take a summer night. it took many people in reddit history. it's just not the best"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " game of thrones is a great way of the "
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='worldnews', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'sure.', u'but', u'you', u\"shouldn't\")\n",
        "have the capacity to fight isis, here's the us and cuba nationalize all the other rovers on the other side of the argument. kennedy said the arabs have been living on your shenanigans. most of the big picture of mohammad? ok then, must be informed these people would have needed and that is just innocuous objects while you can see by a shady international campaign lol sales tax can only make the non stop? wasnt the government he's going to be angry. the other way around, are doing so because they have no business model? many people would fight its not much above poster didn't need to see a real beating each other is completely out as possible. the other side though. your submission was just asking me to see people being taken longer than obama administration believes in the world were so resistant to harsh herbasides. this is the initiation of the northern marianas, a lot more against modern society, anyone who pays them from leaving legally, on this topic is a very valid they will have changed in a free service to football. just the proven guilty. so the wrong types of people i know. so they hit homeowners rather than their actual genes. one of the biggest financial problems that are in deep shit. we should go into comedy. montreal police brutality. a few of the seats are assigned such an awesome surgeon and not the kind of person that was a megathrust [teletsunami](https://en.wikipedia.org/wiki/teletsunami) from the economy, and the [wiki on the table. he should definitely a pretty big thing to remember it by. just say republican politics: people who are neither do you mean by lgbt nonsense that the same thing? buerocracy chasing it's time and refused to be more deadly than illegal ones. i would "
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='halflife', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'to', u'make', u'money', u'after')\n",
        "its release. he likes games and because they enjoy it. instead of the best services in the late '90s or early 2000s. steam (which they are at it. instead of seeing it because they know people technically choose what pc gaming is, let alone what they would rather than gambling on several years rather than gambling on stuff like the game. if you don't think they do you don't want to admire how the game on something that even know people technically choose what happen once they are at it. **edit:** to admire how clever they enjoy it. **edit:** to their money and valve does. &gt;2032 ftfy adorable i'm pretty intelligent model. ubisoft takes a new counter-strike once they work on, but they are at it. instead of other things. it makes a few assets that isn't picking up modding half-life back and make money after its release. he likes games and some value in the game. if you don't understand how the best games as many games that make them money in the game. if you work on something that they have a few assets that high. &gt;&gt;real valve does. &gt;2032 ftfy adorable i'm pretty intelligent model. ubisoft takes a flawed idea, but they've put the best games that they do it when it was on valve's business after the game. if you work on, but you work on certain projects by any means, but gabe \"encourages\" people technically choose to admire how the community for the people to be finished first. source 2 will release a business after its release. he likes to be finished first. source 2, steam vr is obvious. it's convenient for several years rather than pushing out there (i think they do it because they enjoy it. they work on certain projects by satan, "
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='machinelearning', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'too', u'for', u'fun.', u'probably')\n",
        "broken in theano too for finding different useful such dual optimization problems. - using kkt conditions and lots more likely to anything (unless i guess performance will never matter to take an application of that like image and then do something on 3-d here: http://arxiv.org/pdf/1505.02890.pdf thanks! i think that like image and a lot of it will never matter to us appears: by accurately inferring the prediction is mainly useful if anyone is to write titles that one also recently added distributed dataframes for folks that like the same algorithm at the experts understand the experts understand includes literally the same algorithm at amazon (pat bajari), microsoft (susan athey), and bernstein, and bernstein, and then do you could theoretically prevent people from video games where it's not want to take an image and over again... and bernstein, and over and that like remove the same time? i've seen at the tails. - analyze things in their use first order stochastic optimization problems. - use alternating minimization for fun. probably broken in a good model is: p(d | x) = 1.0 i guess performance will never matter to predict the prediction is an application of that google could theoretically prevent people published essentially the task is it will never matter to take an application of bm is an image and do something on the rest to me like pandas and do something like image editing. i.e. you can, throw the rest to anything (unless i could see it just now, so many people from a vector space, it's cool work though. &gt;word2vec is rendered) and a fair point, i'm not familiar with highly refined data from berkeley, one from another, automatic process. here\u2019s where those on shots from a big here, people published essentially the same algorithm to predict the whole "
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='space', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'is', u'lower', u'than', u'the')\n",
        "escape the earth's non spherical nature perturb the same purpose though; it just seems really immature the moon is a direct people about them something recently frozen as the red giant with a ball that was usable iron ore. if they know? i was hoping for \"big ass telescope.\" aka the way from what you don't want to pancake into one it is suffered a point before the body froze solid and i showed the sun (and began falling back) the earth's relative velocity of light is a better chance at the graphs at this gif was created and will never created and will have it is here, so it had instrument and it's still be the ideal counterweight for me, then so insanely high tech electronics without the earth's gravitational pull and after the dissolved gases erupt from dawn but how come they are not as you can get. venus is a direct consequence. but how does a great gif. :) [deleted] two american ones (spacex' [dragon v2](https://en.wikipedia.org/wiki/dragon_v2), boeing's [cst-100](https://en.wikipedia.org/wiki/cst-100)), under thrust, and it's not a lot of love around a form of [sls](https://en.wikipedia.org/wiki/space_launch_system). it can take a very long as a warp drive here is in a singularity, gravity well. there at *one* specific stage of light delay, you don't want to identify parts... any of money to the argument of perigee, the first utilization of a colony floating city on the exhaust particles reached their speed of the way in that many of a [molniya orbit](https://en.wikipedia.org/wiki/molniya_orbit)? one (hardscifi writer)scifi book that was roughly 7 inches representing mars. at the same rate the earth's magnetic poles when you use it in space that the standard model is a better chance at least you process it could be as if implying that this star is about torque-induced precession being "
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngram_subgenerator(subreddit='conspiracy', length=300, temp=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(u'magic', u'in', u'order', u'to')\n",
        "preserve your account, it and coming up to the mods of a stranger who benefited from the real conspiracies behind this. i can imagine that--fox tells the video was never an era](https://medium.com/@b_k/https-the-end-of-an-era-c106acded474) i was late now). i don't expect this is on the image might not be surprised one end of an acute issue, i'm sure he has to resort to the media and this seemed like what isis has been dealing with the revelations learned from the ocean floor, briefly leaving a whole branch of his new money is printed 04-2016. if you have any questions about how he was trying to articulate a good enough so it actually believes that. absolutely. yeah, i'm sick is a colloquial term. you're referring to. anyway, i have in this thread. funny man. looking at your herping and derping will make is what should need to control? the np domain can handle that. but no consistent trend to a specific person, you a sjw; i think there are certain triggers that i was in the sky by the way. for the most part and the accounts as in the media. i think it's the right to the media is a retard. you know there are extra sensitive to the chair should get recycled all we have enough traces on a search for money a lot better than that. but whats breaking the \"personal attack\" in the /r/pics thread: \"you are the bad guys. knights of the state.\" -randolph bourne who think you're right of that position. i am on the moon landing, then the doom and their many scenes, people are seeding synonymous with an answer? does provide full power. and if they want people that claim this helps to use the internet'/ 'total supporters' the moon landing, then move is why "
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}